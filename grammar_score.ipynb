{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b26b506c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mdriz\\anaconda3\\Lib\\site-packages\\transformers\\utils\\generic.py:260: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import librosa\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from transformers import pipeline, AutoModelForSequenceClassification, AutoTokenizer\n",
    "import language_tool_python\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "import pickle\n",
    "import joblib\n",
    "from IPython.display import display, Markdown\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22faf5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Copy the entire AudioGrammarScoringModel class here\n",
    "class AudioGrammarScoringModel:\n",
    "    def __init__(self, base_path='./'):\n",
    "        \"\"\"\n",
    "        Initialize the model with paths to the competition data\n",
    "        \n",
    "        Args:\n",
    "            base_path: Base path containing the data folders\n",
    "        \"\"\"\n",
    "        self.base_path = base_path\n",
    "        self.audio_path = os.path.join(base_path, 'audios/train/')\n",
    "        self.test_audio_path = os.path.join(base_path, 'audios/test/')\n",
    "        self.train_data = None\n",
    "        self.test_data = None\n",
    "        self.features_df = None\n",
    "        self.model = None\n",
    "        \n",
    "        # Initialize ASR model (using Whisper for good accuracy)\n",
    "        print(\"Initializing ASR model...\")\n",
    "        self.asr = pipeline(\"automatic-speech-recognition\", model=\"openai/whisper-base\")\n",
    "        \n",
    "        # Initialize grammar checker\n",
    "        print(\"Initializing grammar checker...\")\n",
    "        self.grammar_tool = language_tool_python.LanguageTool('en-US')\n",
    "        \n",
    "        # Initialize pre-trained model for linguistic quality assessment\n",
    "        print(\"Initializing linguistic quality model...\")\n",
    "        model_name = \"textattack/roberta-base-CoLA\"\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.quality_model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "        \n",
    "        print(\"Initialization complete!\")\n",
    "        \n",
    "    def load_data(self, train_file='train.csv', test_file='test.csv'):\n",
    "        \"\"\"Load training and test data\"\"\"\n",
    "        train_path = os.path.join(self.base_path, train_file)\n",
    "        test_path = os.path.join(self.base_path, test_file)\n",
    "        \n",
    "        # Load training data\n",
    "        if os.path.exists(train_path):\n",
    "            self.train_data = pd.read_csv(train_path, na_values=[''], keep_default_na=True)\n",
    "            # Fill any missing values with 0\n",
    "            self.train_data = self.train_data.fillna(0)\n",
    "            # Ensure column names are standardized\n",
    "            if 'filename' in self.train_data.columns and 'label' in self.train_data.columns:\n",
    "                self.train_data = self.train_data.rename(columns={\n",
    "                    'filename': 'audio_file',\n",
    "                    'label': 'grammar_score'\n",
    "                })\n",
    "            print(f\"Loaded {len(self.train_data)} training samples\")\n",
    "        else:\n",
    "            print(f\"Warning: Training file {train_path} not found.\")\n",
    "            \n",
    "        # Load test data\n",
    "        if os.path.exists(test_path):\n",
    "            self.test_data = pd.read_csv(test_path, na_values=[''], keep_default_na=True)\n",
    "            # Fill any missing values with 0\n",
    "            self.test_data = self.test_data.fillna(0)\n",
    "            # Ensure column names are standardized\n",
    "            if 'filename' in self.test_data.columns:\n",
    "                self.test_data = self.test_data.rename(columns={\n",
    "                    'filename': 'audio_file'\n",
    "                })\n",
    "            print(f\"Loaded {len(self.test_data)} test samples\")\n",
    "        else:\n",
    "            print(f\"Warning: Test file {test_path} not found.\")\n",
    "            \n",
    "        # Display the first few rows to understand the data structure\n",
    "        if self.train_data is not None:\n",
    "            display(Markdown(\"### Training data sample:\"))\n",
    "            display(self.train_data.head())\n",
    "            \n",
    "            # Analyze the distribution of grammar scores\n",
    "            display(Markdown(\"### Grammar score distribution:\"))\n",
    "            display(self.train_data['grammar_score'].describe())\n",
    "            \n",
    "            # Create a histogram of grammar scores\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            sns.histplot(self.train_data['grammar_score'], bins=10, kde=True)\n",
    "            plt.title('Distribution of Grammar Scores')\n",
    "            plt.xlabel('Grammar Score')\n",
    "            plt.ylabel('Count')\n",
    "            plt.show()\n",
    "        \n",
    "    def extract_features(self, data_type='train', subset=None, force_recompute=False, save_features=True):\n",
    "        \"\"\"\n",
    "        Extract features from audio files\n",
    "\n",
    "        Args:\n",
    "            data_type: 'train' or 'test' to specify which dataset to process\n",
    "            subset: Number of samples to process (for testing), None for all\n",
    "            force_recompute: If True, recompute features even if saved features exist\n",
    "            save_features: If True, save features to disk after computation\n",
    "        \"\"\"\n",
    "        # Check if features already exist\n",
    "        features_path = os.path.join(self.base_path, f'{data_type}_features.pkl')\n",
    "\n",
    "        if os.path.exists(features_path) and not force_recompute:\n",
    "            print(f\"Loading pre-computed features from {features_path}\")\n",
    "            with open(features_path, 'rb') as f:\n",
    "                features_df = pickle.load(f)\n",
    "\n",
    "            if subset is not None:\n",
    "                features_df = features_df.head(subset)\n",
    "\n",
    "            if data_type == 'train':\n",
    "                self.features_df = features_df\n",
    "\n",
    "            return features_df\n",
    "\n",
    "        # Select the appropriate dataset and audio path\n",
    "        if data_type == 'train':\n",
    "            if self.train_data is None:\n",
    "                raise ValueError(\"Training data not loaded. Call load_data() first.\")\n",
    "            data = self.train_data\n",
    "            audio_path = self.train_audio_path  # Use train audio path\n",
    "        elif data_type == 'test':\n",
    "            if self.test_data is None:\n",
    "                raise ValueError(\"Test data not loaded. Call load_data() first.\")\n",
    "            data = self.test_data\n",
    "            audio_path = self.test_audio_path  # Use test audio path\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid data_type: {data_type}. Must be 'train' or 'test'.\")\n",
    "\n",
    "        # Create a subset for testing if specified\n",
    "        if subset is not None:\n",
    "            data = data[:subset].copy()\n",
    "        else:\n",
    "            data = data.copy()\n",
    "\n",
    "        features = []\n",
    "\n",
    "        print(f\"Extracting features from {data_type} audio files...\")\n",
    "        for idx, row in tqdm(data.iterrows(), total=len(data)):\n",
    "            audio_file = row['audio_file']\n",
    "            file_audio_path = os.path.join(audio_path, audio_file)  # Use the appropriate audio path\n",
    "\n",
    "            # Skip if file doesn't exist\n",
    "            if not os.path.exists(file_audio_path):\n",
    "                print(f\"Warning: {file_audio_path} not found. Skipping.\")\n",
    "                continue\n",
    "\n",
    "            # Process audio file\n",
    "            feature_dict = self._process_audio_file(file_audio_path)\n",
    "\n",
    "            # Add file information\n",
    "            feature_dict['audio_file'] = audio_file\n",
    "\n",
    "            # Add the ground truth score if available\n",
    "            if 'grammar_score' in row:\n",
    "                feature_dict['grammar_score'] = row['grammar_score']\n",
    "\n",
    "            features.append(feature_dict)\n",
    "    \n",
    "    # Rest of the method remains the same\n",
    "    # ...\n",
    "        \n",
    "        # Convert to DataFrame\n",
    "        features_df = pd.DataFrame(features)\n",
    "        \n",
    "        # Store the features\n",
    "        if data_type == 'train':\n",
    "            self.features_df = features_df\n",
    "        \n",
    "        # Save features to disk if requested\n",
    "        if save_features:\n",
    "            with open(features_path, 'wb') as f:\n",
    "                pickle.dump(features_df, f)\n",
    "            print(f\"Saved features to {features_path}\")\n",
    "        \n",
    "        print(f\"Extracted features for {len(features_df)} audio files\")\n",
    "        \n",
    "        # Display feature correlation with grammar score if available\n",
    "        if 'grammar_score' in features_df.columns and len(features_df) > 0:\n",
    "            display(Markdown(\"### Feature correlation with grammar score:\"))\n",
    "            # Convert string columns to numeric, dropping non-numeric columns\n",
    "            numeric_df = features_df.select_dtypes(include=[np.number])\n",
    "            if 'grammar_score' in numeric_df.columns:\n",
    "                correlations = numeric_df.corr()['grammar_score'].sort_values(ascending=False)\n",
    "                display(correlations)\n",
    "                \n",
    "                # Create correlation heatmap\n",
    "                plt.figure(figsize=(12, 10))\n",
    "                correlation_matrix = numeric_df.corr()\n",
    "                mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))\n",
    "                sns.heatmap(correlation_matrix, mask=mask, annot=False, cmap='coolwarm', \n",
    "                          fmt='.2f', square=True, linewidths=.5)\n",
    "                plt.title('Feature Correlation Matrix')\n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "        \n",
    "        return features_df\n",
    "    \n",
    "    # Include all other methods from the original class here\n",
    "    def _process_audio_file(self, audio_path):\n",
    "        \"\"\"Process a single audio file to extract features\"\"\"\n",
    "        feature_dict = {}\n",
    "        \n",
    "        try:\n",
    "            # Load audio\n",
    "            audio, sr = librosa.load(audio_path, sr=16000)\n",
    "            \n",
    "            # Extract audio features\n",
    "            feature_dict.update(self._extract_audio_features(audio, sr))\n",
    "            \n",
    "            # Transcribe audio with timestamp handling for long files\n",
    "            try:\n",
    "                transcription = self.asr(\n",
    "                    {\"array\": audio, \"sampling_rate\": sr},\n",
    "                    return_timestamps=True,  # Enable timestamp handling for long files\n",
    "                    chunk_length_s=30  # Process in 30-second chunks\n",
    "                )\n",
    "                \n",
    "                # Extract text from the transcription\n",
    "                if isinstance(transcription, dict):\n",
    "                    if \"text\" in transcription:\n",
    "                        text = transcription[\"text\"]\n",
    "                    elif \"chunks\" in transcription:\n",
    "                        # Combine text from chunks for long audio files\n",
    "                        text = \" \".join([chunk[\"text\"] for chunk in transcription[\"chunks\"]])\n",
    "                    else:\n",
    "                        text = \"\"\n",
    "                else:\n",
    "                    text = str(transcription)\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"ASR Error for {audio_path}: {str(e)}\")\n",
    "                text = \"\"\n",
    "            \n",
    "            feature_dict['transcription'] = text.strip()\n",
    "            \n",
    "            # Extract text features only if we have transcription\n",
    "            if text:\n",
    "                feature_dict.update(self._extract_text_features(text))\n",
    "            else:\n",
    "                # Add default text feature values\n",
    "                feature_dict.update({\n",
    "                    'word_count': 0,\n",
    "                    'error_count': 0,\n",
    "                    'error_density': 0,\n",
    "                    'sentence_count': 0,\n",
    "                    'avg_sentence_length': 0,\n",
    "                    'linguistic_quality': 0\n",
    "                })\n",
    "            \n",
    "            # Calculate speech rate now that we have both duration and word count\n",
    "            if feature_dict['duration'] > 0:\n",
    "                feature_dict['speech_rate'] = feature_dict['word_count'] / (feature_dict['duration'] / 60.0)  # words per minute\n",
    "            else:\n",
    "                feature_dict['speech_rate'] = 0\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {audio_path}: {e}\")\n",
    "            # Set default values if processing fails\n",
    "            feature_dict = {\n",
    "                'duration': 0,\n",
    "                'mean_energy': 0,\n",
    "                'tempo': 0,\n",
    "                'zero_crossing_rate': 0,\n",
    "                'speech_rate': 0,\n",
    "                'word_count': 0,\n",
    "                'error_count': 0,\n",
    "                'error_density': 0,\n",
    "                'sentence_count': 0,\n",
    "                'avg_sentence_length': 0,\n",
    "                'linguistic_quality': 0,\n",
    "                'transcription': ''\n",
    "            }\n",
    "            \n",
    "        return feature_dict\n",
    "    \n",
    "    def _extract_audio_features(self, audio, sr):\n",
    "        \"\"\"Extract features from audio signal\"\"\"\n",
    "        features = {}\n",
    "        \n",
    "        # Duration\n",
    "        features['duration'] = librosa.get_duration(y=audio, sr=sr)\n",
    "        \n",
    "        # Energy features\n",
    "        features['mean_energy'] = np.mean(np.abs(audio))\n",
    "        \n",
    "        # Tempo estimation\n",
    "        onset_env = librosa.onset.onset_strength(y=audio, sr=sr)\n",
    "        tempo = librosa.beat.tempo(onset_envelope=onset_env, sr=sr)[0]\n",
    "        features['tempo'] = tempo\n",
    "        \n",
    "        # Zero crossing rate\n",
    "        zcr = librosa.feature.zero_crossing_rate(audio)\n",
    "        features['zero_crossing_rate'] = np.mean(zcr)\n",
    "        \n",
    "        # Spectral features\n",
    "        spectral_centroid = librosa.feature.spectral_centroid(y=audio, sr=sr)\n",
    "        features['spectral_centroid_mean'] = np.mean(spectral_centroid)\n",
    "        \n",
    "        spectral_bandwidth = librosa.feature.spectral_bandwidth(y=audio, sr=sr)\n",
    "        features['spectral_bandwidth_mean'] = np.mean(spectral_bandwidth)\n",
    "        \n",
    "        # RMS energy\n",
    "        rms = librosa.feature.rms(y=audio)\n",
    "        features['rms_mean'] = np.mean(rms)\n",
    "        \n",
    "        # MFCC features (aggregate statistics)\n",
    "        mfccs = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=13)\n",
    "        for i in range(13):\n",
    "            features[f'mfcc{i+1}_mean'] = np.mean(mfccs[i])\n",
    "            features[f'mfcc{i+1}_std'] = np.std(mfccs[i])\n",
    "        \n",
    "        return features\n",
    "    \n",
    "    def _extract_text_features(self, text):\n",
    "        \"\"\"Extract features from transcribed text\"\"\"\n",
    "        features = {}\n",
    "        \n",
    "        # Basic text stats\n",
    "        words = text.split()\n",
    "        features['word_count'] = len(words)\n",
    "        \n",
    "        # Grammar errors\n",
    "        grammar_errors = self.grammar_tool.check(text)\n",
    "        features['error_count'] = len(grammar_errors)\n",
    "        features['error_density'] = features['error_count'] / max(1, features['word_count'])\n",
    "        \n",
    "        # Sentence features\n",
    "        sentences = [s.strip() for s in text.split('.') if s.strip()]\n",
    "        features['sentence_count'] = len(sentences)\n",
    "        features['avg_sentence_length'] = features['word_count'] / max(1, features['sentence_count'])\n",
    "        \n",
    "        # Word length statistics\n",
    "        if words:\n",
    "            word_lengths = [len(word) for word in words]\n",
    "            features['avg_word_length'] = sum(word_lengths) / len(words)\n",
    "            features['max_word_length'] = max(word_lengths) if word_lengths else 0\n",
    "        else:\n",
    "            features['avg_word_length'] = 0\n",
    "            features['max_word_length'] = 0\n",
    "        \n",
    "        # Linguistic quality assessment\n",
    "        features['linguistic_quality'] = self._assess_linguistic_quality(text)\n",
    "        \n",
    "        # Extract specific grammar error types\n",
    "        error_categories = {}\n",
    "        for error in grammar_errors:\n",
    "            category = error.ruleIssueType if hasattr(error, 'ruleIssueType') else 'other'\n",
    "            error_categories[category] = error_categories.get(category, 0) + 1\n",
    "            \n",
    "        # Add top error categories as features\n",
    "        for category, count in error_categories.items():\n",
    "            safe_category = ''.join(c if c.isalnum() else '_' for c in category)\n",
    "            features[f'error_{safe_category}'] = count\n",
    "            \n",
    "        # Additional linguistic features\n",
    "        if text:\n",
    "            features['unique_words_ratio'] = len(set(words)) / max(1, len(words))\n",
    "            \n",
    "            # Count punctuation marks\n",
    "            features['comma_count'] = text.count(',')\n",
    "            features['question_mark_count'] = text.count('?')\n",
    "            features['exclamation_count'] = text.count('!')\n",
    "            \n",
    "            # Count specific parts of speech (simplified)\n",
    "            features['pronoun_count'] = sum(1 for word in words if word.lower() in ['i', 'me', 'my', 'mine', 'you', 'your', 'yours', 'he', 'him', 'his', 'she', 'her', 'hers', 'it', 'its', 'we', 'us', 'our', 'ours', 'they', 'them', 'their', 'theirs'])\n",
    "            features['article_count'] = sum(1 for word in words if word.lower() in ['a', 'an', 'the'])\n",
    "            features['conjunction_count'] = sum(1 for word in words if word.lower() in ['and', 'but', 'or', 'nor', 'for', 'yet', 'so', 'although', 'because', 'since', 'unless'])\n",
    "        else:\n",
    "            features['unique_words_ratio'] = 0\n",
    "            features['comma_count'] = 0\n",
    "            features['question_mark_count'] = 0\n",
    "            features['exclamation_count'] = 0\n",
    "            features['pronoun_count'] = 0\n",
    "            features['article_count'] = 0\n",
    "            features['conjunction_count'] = 0\n",
    "            \n",
    "        return features\n",
    "    \n",
    "    def _assess_linguistic_quality(self, text):\n",
    "        \"\"\"Use a pre-trained model to assess linguistic acceptability\"\"\"\n",
    "        if not text.strip():\n",
    "            return 0\n",
    "            \n",
    "        inputs = self.tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "        with torch.no_grad():\n",
    "            outputs = self.quality_model(**inputs)\n",
    "        \n",
    "        # Get the predicted score (higher means more grammatically acceptable)\n",
    "        acceptability_score = torch.softmax(outputs.logits, dim=1)[0][1].item()\n",
    "        return acceptability_score\n",
    "    \n",
    "    def prepare_model_data(self, features_df=None, is_test=False):\n",
    "        \"\"\"Prepare data for model training\"\"\"\n",
    "        if features_df is None:\n",
    "            features_df = self.features_df\n",
    "        \n",
    "        if features_df is None or len(features_df) == 0:\n",
    "            raise ValueError(\"No features available. Run extract_features() first.\")\n",
    "        \n",
    "        # Drop rows with missing values\n",
    "        if not is_test:\n",
    "            features_df = features_df.dropna(subset=['grammar_score'])\n",
    "        \n",
    "        # Select numeric columns only, excluding 'grammar_score' and non-feature columns\n",
    "        exclude_cols = ['audio_file', 'grammar_score', 'transcription']\n",
    "        feature_cols = [col for col in features_df.select_dtypes(include=[np.number]).columns \n",
    "                       if col not in exclude_cols]\n",
    "        \n",
    "        # Prepare X (features) and y (target)\n",
    "        X = features_df[feature_cols]\n",
    "        y = features_df['grammar_score']\n",
    "        \n",
    "        # Fill any remaining NaN values with 0\n",
    "        X = X.fillna(0)\n",
    "        \n",
    "        print(f\"Prepared {len(X)} samples with {len(feature_cols)} features\")\n",
    "        return X, y\n",
    "    \n",
    "    def train_with_cross_validation(self, cv=5, model_type='xgboost'):\n",
    "        \"\"\"Train and evaluate model with cross-validation\"\"\"\n",
    "        print(\"Training with {}-fold cross-validation...\".format(cv))\n",
    "        \n",
    "        # Prepare data\n",
    "        try:\n",
    "            X, y = self.prepare_model_data()\n",
    "        except ValueError as e:\n",
    "            print(f\"Error preparing data: {e}\")\n",
    "            return\n",
    "        \n",
    "        if len(X) < cv:\n",
    "            print(f\"Error: Not enough samples ({len(X)}) for {cv}-fold cross-validation\")\n",
    "            return\n",
    "        \n",
    "        # Initialize model\n",
    "        if model_type.lower() == 'xgboost':\n",
    "            model = XGBRegressor(\n",
    "                n_estimators=100,\n",
    "                learning_rate=0.1,\n",
    "                max_depth=5,\n",
    "                random_state=42\n",
    "            )\n",
    "        else:\n",
    "            model = RandomForestRegressor(\n",
    "                n_estimators=100,\n",
    "                max_depth=10,\n",
    "                random_state=42\n",
    "            )\n",
    "        \n",
    "        # Perform cross-validation\n",
    "        kf = KFold(n_splits=cv, shuffle=True, random_state=42)\n",
    "        mse_scores = []\n",
    "        mae_scores = []\n",
    "        \n",
    "        for fold, (train_idx, val_idx) in enumerate(kf.split(X)):\n",
    "            X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "            y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "            \n",
    "            # Train model\n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "            # Make predictions\n",
    "            y_pred = model.predict(X_val)\n",
    "            \n",
    "            # Calculate metrics\n",
    "            mse = mean_squared_error(y_val, y_pred)\n",
    "            mae = mean_absolute_error(y_val, y_pred)\n",
    "            \n",
    "            mse_scores.append(mse)\n",
    "            mae_scores.append(mae)\n",
    "            \n",
    "            print(f\"Fold {fold + 1}: MSE = {mse:.4f}, MAE = {mae:.4f}\")\n",
    "        \n",
    "        # Print average scores\n",
    "        print(\"\\nCross-validation results:\")\n",
    "        print(f\"Average MSE: {np.mean(mse_scores):.4f} (+/- {np.std(mse_scores):.4f})\")\n",
    "        print(f\"Average MAE: {np.mean(mae_scores):.4f} (+/- {np.std(mae_scores):.4f})\")\n",
    "        \n",
    "        # Train final model on all data\n",
    "        return self.train_model(model_type)\n",
    "    \n",
    "    def train_model(self, model_type='xgboost'):\n",
    "        \"\"\"Train a model to predict grammar scores on all training data\"\"\"\n",
    "        X, y = self.prepare_model_data()\n",
    "        \n",
    "        print(f\"Training final {model_type} model on all {len(X)} samples...\")\n",
    "        \n",
    "        if model_type == 'random_forest':\n",
    "            model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "        elif model_type == 'xgboost':\n",
    "            model = XGBRegressor(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown model type: {model_type}\")\n",
    "        \n",
    "        # Train the model\n",
    "        print(\"Model training Started\")\n",
    "        model.fit(X, y)\n",
    "        self.model = model\n",
    "        \n",
    "        # Feature importance\n",
    "        if hasattr(model, 'feature_importances_'):\n",
    "            importances = pd.DataFrame({\n",
    "                'feature': X.columns,\n",
    "                'importance': model.feature_importances_\n",
    "            }).sort_values('importance', ascending=False)\n",
    "            \n",
    "            display(Markdown(\"### Top 10 most important features:\"))\n",
    "            display(importances.head(10))\n",
    "            \n",
    "            # Plot feature importance\n",
    "            plt.figure(figsize=(12, 8))\n",
    "            top_features = importances.head(20)\n",
    "            sns.barplot(x='importance', y='feature', data=top_features)\n",
    "            plt.title('Top 20 Feature Importances')\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "        return model\n",
    "    \n",
    "    def save_model(self, model_path='grammar_scoring_model.joblib'):\n",
    "        \"\"\"Save the trained model to disk\"\"\"\n",
    "        if self.model is None:\n",
    "            raise ValueError(\"Model not trained. Call train_model() first.\")\n",
    "            \n",
    "        joblib.dump(self.model, model_path)\n",
    "        print(f\"Model saved to {model_path}\")\n",
    "        \n",
    "    def load_model(self, model_path='grammar_scoring_model.joblib'):\n",
    "        \"\"\"Load a trained model from disk\"\"\"\n",
    "        if os.path.exists(model_path):\n",
    "            self.model = joblib.load(model_path)\n",
    "            print(f\"Model loaded from {model_path}\")\n",
    "            return True\n",
    "        else:\n",
    "            print(f\"Model file {model_path} not found.\")\n",
    "            return False\n",
    "    \n",
    "    def predict_single(self, audio_path):\n",
    "        \"\"\"Predict grammar score for a single audio file\"\"\"\n",
    "        if self.model is None:\n",
    "            raise ValueError(\"Model not trained. Call train_model() or load_model() first.\")\n",
    "\n",
    "        # Process the audio file\n",
    "        features = self._process_audio_file(audio_path)\n",
    "\n",
    "        # Prepare features for prediction\n",
    "        feature_df = pd.DataFrame([features])\n",
    "\n",
    "        # Get the feature names that the model was trained on\n",
    "        if hasattr(self.model, 'feature_names_in_'):\n",
    "            required_features = self.model.feature_names_in_\n",
    "        else:\n",
    "            # If model doesn't store feature names, we need to extract them\n",
    "            # from training data or use a different approach\n",
    "            X_train, _ = self.prepare_model_data(self.features_df)\n",
    "            required_features = X_train.columns\n",
    "\n",
    "        # Create a DataFrame with all required features, filling missing ones with 0\n",
    "        X_pred = pd.DataFrame(0, index=[0], columns=required_features)\n",
    "\n",
    "        # Fill in the values we have\n",
    "        for col in feature_df.columns:\n",
    "            if col in required_features:\n",
    "                X_pred[col] = feature_df[col]\n",
    "\n",
    "        # Make prediction\n",
    "        prediction = self.model.predict(X_pred)[0]\n",
    "\n",
    "        return {\n",
    "            'transcription': features.get('transcription', ''),\n",
    "            'predicted_score': round(prediction, 2),\n",
    "            'features': features\n",
    "        }\n",
    "    \n",
    "    def predict_test_set(self):\n",
    "        \"\"\"Predict grammar scores for the test set\"\"\"\n",
    "        if self.model is None:\n",
    "            raise ValueError(\"Model not trained. Call train_model() or load_model() first.\")\n",
    "\n",
    "        # Process test files if not already done\n",
    "        if self.test_data is None:\n",
    "            raise ValueError(\"Test data not loaded. Call load_data() first.\")\n",
    "\n",
    "        # Extract features from test files if needed\n",
    "        test_features = self.extract_features(data_type='test')\n",
    "\n",
    "        # Prepare features for prediction - CHANGE THIS LINE\n",
    "        X_test, _ = self.prepare_model_data(test_features, is_test=True)\n",
    "\n",
    "        # Make predictions\n",
    "        predictions = self.model.predict(X_test)\n",
    "\n",
    "        # Create results dataframe\n",
    "        results = pd.DataFrame({\n",
    "            'audio_file': test_features['audio_file'],\n",
    "            'predicted_score': predictions,\n",
    "            'transcription': test_features['transcription']\n",
    "        })\n",
    "\n",
    "        return results\n",
    "    \n",
    "    def generate_submission(self, output_file='submission.csv'):\n",
    "        \"\"\"Generate submission file for Kaggle competition\"\"\"\n",
    "        results = self.predict_test_set()\n",
    "\n",
    "        # Create a submission dataframe with the required format\n",
    "        submission = pd.DataFrame({\n",
    "            'filename': results['audio_file'],\n",
    "            'label': results['predicted_score']\n",
    "        })\n",
    "\n",
    "        # Clip to range [2, 5] and round to nearest 0.5\n",
    "        submission['label'] = submission['label'].clip(2, 5)\n",
    "        submission['label'] = (submission['label'] * 2).round() / 2\n",
    "\n",
    "        # Save to CSV\n",
    "        submission.to_csv(output_file, index=False)\n",
    "        print(f\"Submission file created: {output_file}\")\n",
    "\n",
    "        return submission\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a0bbfb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing ASR model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mdriz\\anaconda3\\Lib\\site-packages\\transformers\\utils\\generic.py:260: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing grammar checker...\n",
      "Initializing linguistic quality model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mdriz\\anaconda3\\Lib\\site-packages\\transformers\\modeling_utils.py:479: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(checkpoint_file, map_location=map_location)\n",
      "Some weights of the model checkpoint at textattack/roberta-base-CoLA were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialization complete!\n"
     ]
    }
   ],
   "source": [
    "base_path = './'  # Change this to your actual data directory\n",
    "model = AudioGrammarScoringModel(base_path=base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5924f79d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 444 training samples\n",
      "Loaded 204 test samples\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Training data sample:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>audio_file</th>\n",
       "      <th>grammar_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>audio_710.wav</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>audio_1265.wav</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>audio_1114.wav</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>audio_946.wav</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>audio_1127.wav</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       audio_file  grammar_score\n",
       "0   audio_710.wav            1.0\n",
       "1  audio_1265.wav            1.0\n",
       "2  audio_1114.wav            1.5\n",
       "3   audio_946.wav            1.5\n",
       "4  audio_1127.wav            2.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Grammar score distribution:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "count    444.000000\n",
       "mean       3.967342\n",
       "std        1.048784\n",
       "min        1.000000\n",
       "25%        3.000000\n",
       "50%        4.000000\n",
       "75%        5.000000\n",
       "max        5.000000\n",
       "Name: grammar_score, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.load_data(train_file='train.csv', test_file='test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32bdb283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pre-computed features from ./train_features.pkl\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>mean_energy</th>\n",
       "      <th>tempo</th>\n",
       "      <th>zero_crossing_rate</th>\n",
       "      <th>spectral_centroid_mean</th>\n",
       "      <th>spectral_bandwidth_mean</th>\n",
       "      <th>rms_mean</th>\n",
       "      <th>mfcc1_mean</th>\n",
       "      <th>mfcc1_std</th>\n",
       "      <th>mfcc2_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>conjunction_count</th>\n",
       "      <th>speech_rate</th>\n",
       "      <th>audio_file</th>\n",
       "      <th>grammar_score</th>\n",
       "      <th>error_misspelling</th>\n",
       "      <th>error_uncategorized</th>\n",
       "      <th>error_grammar</th>\n",
       "      <th>error_duplication</th>\n",
       "      <th>error_locale_violation</th>\n",
       "      <th>error_whitespace</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60.074688</td>\n",
       "      <td>0.022917</td>\n",
       "      <td>133.928571</td>\n",
       "      <td>0.150859</td>\n",
       "      <td>1652.834782</td>\n",
       "      <td>1421.570396</td>\n",
       "      <td>0.031372</td>\n",
       "      <td>-340.821472</td>\n",
       "      <td>80.339378</td>\n",
       "      <td>87.854080</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>123.845838</td>\n",
       "      <td>audio_710.wav</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60.074688</td>\n",
       "      <td>0.010485</td>\n",
       "      <td>110.294118</td>\n",
       "      <td>0.143139</td>\n",
       "      <td>1812.681453</td>\n",
       "      <td>1710.677609</td>\n",
       "      <td>0.015064</td>\n",
       "      <td>-485.992737</td>\n",
       "      <td>127.466263</td>\n",
       "      <td>50.111820</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>169.788649</td>\n",
       "      <td>audio_1265.wav</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60.074688</td>\n",
       "      <td>0.014858</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>0.132682</td>\n",
       "      <td>2126.143258</td>\n",
       "      <td>1593.561943</td>\n",
       "      <td>0.021168</td>\n",
       "      <td>-468.621979</td>\n",
       "      <td>139.220428</td>\n",
       "      <td>55.773441</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>47.940324</td>\n",
       "      <td>audio_1114.wav</td>\n",
       "      <td>1.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60.074688</td>\n",
       "      <td>0.028304</td>\n",
       "      <td>156.250000</td>\n",
       "      <td>0.105385</td>\n",
       "      <td>1962.232377</td>\n",
       "      <td>1590.935140</td>\n",
       "      <td>0.037655</td>\n",
       "      <td>-418.862366</td>\n",
       "      <td>134.786011</td>\n",
       "      <td>24.498125</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>38.951513</td>\n",
       "      <td>audio_946.wav</td>\n",
       "      <td>1.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60.074688</td>\n",
       "      <td>0.035534</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>0.155081</td>\n",
       "      <td>1751.896484</td>\n",
       "      <td>1533.526463</td>\n",
       "      <td>0.049667</td>\n",
       "      <td>-339.085052</td>\n",
       "      <td>111.981979</td>\n",
       "      <td>81.655800</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>114.857027</td>\n",
       "      <td>audio_1127.wav</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    duration  mean_energy       tempo  zero_crossing_rate  \\\n",
       "0  60.074688     0.022917  133.928571            0.150859   \n",
       "1  60.074688     0.010485  110.294118            0.143139   \n",
       "2  60.074688     0.014858  125.000000            0.132682   \n",
       "3  60.074688     0.028304  156.250000            0.105385   \n",
       "4  60.074688     0.035534  125.000000            0.155081   \n",
       "\n",
       "   spectral_centroid_mean  spectral_bandwidth_mean  rms_mean  mfcc1_mean  \\\n",
       "0             1652.834782              1421.570396  0.031372 -340.821472   \n",
       "1             1812.681453              1710.677609  0.015064 -485.992737   \n",
       "2             2126.143258              1593.561943  0.021168 -468.621979   \n",
       "3             1962.232377              1590.935140  0.037655 -418.862366   \n",
       "4             1751.896484              1533.526463  0.049667 -339.085052   \n",
       "\n",
       "    mfcc1_std  mfcc2_mean  ...  conjunction_count  speech_rate  \\\n",
       "0   80.339378   87.854080  ...                  0   123.845838   \n",
       "1  127.466263   50.111820  ...                  2   169.788649   \n",
       "2  139.220428   55.773441  ...                  3    47.940324   \n",
       "3  134.786011   24.498125  ...                  4    38.951513   \n",
       "4  111.981979   81.655800  ...                 11   114.857027   \n",
       "\n",
       "       audio_file  grammar_score  error_misspelling  error_uncategorized  \\\n",
       "0   audio_710.wav            1.0                NaN                  NaN   \n",
       "1  audio_1265.wav            1.0                1.0                  NaN   \n",
       "2  audio_1114.wav            1.5                NaN                  2.0   \n",
       "3   audio_946.wav            1.5                NaN                  1.0   \n",
       "4  audio_1127.wav            2.0                NaN                  1.0   \n",
       "\n",
       "   error_grammar  error_duplication  error_locale_violation  error_whitespace  \n",
       "0            NaN                NaN                     NaN               NaN  \n",
       "1            NaN                NaN                     NaN               NaN  \n",
       "2            NaN                NaN                     NaN               NaN  \n",
       "3            NaN                NaN                     NaN               NaN  \n",
       "4            NaN                NaN                     NaN               NaN  \n",
       "\n",
       "[5 rows x 60 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.extract_features(subset=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34b96531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pre-computed features from ./train_features.pkl\n",
      "Loading pre-computed features from ./test_features.pkl\n"
     ]
    }
   ],
   "source": [
    "model.extract_features(force_recompute=False, save_features=True)\n",
    "test_features = model.extract_features(data_type='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea51a717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from grammar_scoring_model.joblib\n"
     ]
    }
   ],
   "source": [
    "# Option 1: Load pre-trained model if available\n",
    "model_path = 'grammar_scoring_model.joblib'\n",
    "model_loaded = model.load_model(model_path)\n",
    "\n",
    "if not model_loaded:\n",
    "    # Option 2: Train a new model\n",
    "    display(Markdown(\"### Training a new model with cross-validation\"))\n",
    "    model.train_with_cross_validation(cv=5, model_type='random_forest')\n",
    "    \n",
    "    # Save the trained model \n",
    "    model.save_model(model_path)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1acf8fcf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1690cd38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ca53872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pre-computed features from ./test_features.pkl\n",
      "Prepared 201 samples with 57 features\n",
      "Submission file created: submission.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>audio_804.wav</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>audio_1028.wav</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>audio_865.wav</td>\n",
       "      <td>2.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>audio_774.wav</td>\n",
       "      <td>2.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>audio_1138.wav</td>\n",
       "      <td>2.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>audio_278.wav</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>audio_1212.wav</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>audio_178.wav</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>audio_542.wav</td>\n",
       "      <td>2.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>audio_248.wav</td>\n",
       "      <td>3.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         filename  label\n",
       "0   audio_804.wav    2.5\n",
       "1  audio_1028.wav    3.0\n",
       "2   audio_865.wav    2.8\n",
       "3   audio_774.wav    2.9\n",
       "4  audio_1138.wav    2.9\n",
       "5   audio_278.wav    3.6\n",
       "6  audio_1212.wav    3.6\n",
       "7   audio_178.wav    4.1\n",
       "8   audio_542.wav    2.9\n",
       "9   audio_248.wav    3.2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get the test features\n",
    "test_features = model.extract_features(data_type='test')\n",
    "\n",
    "# Get the feature names that the model was trained with\n",
    "# We can get these from the model's feature_names_ attribute\n",
    "feature_names = model.model.feature_names_in_\n",
    "\n",
    "# Create a DataFrame with the expected features (filled with zeros)\n",
    "X_test = pd.DataFrame(0, index=range(len(test_features)), columns=feature_names)\n",
    "\n",
    "# Fill in the values where we have them\n",
    "exclude_cols = ['audio_file', 'transcription', 'grammar_score']\n",
    "for col in feature_names:\n",
    "    if col in test_features.columns:\n",
    "        X_test[col] = test_features[col].fillna(0)\n",
    "\n",
    "print(f\"Prepared {len(X_test)} samples with {len(feature_names)} features\")\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.model.predict(X_test)\n",
    "\n",
    "# Create results dataframe\n",
    "results = pd.DataFrame({\n",
    "    'audio_file': test_features['audio_file'],\n",
    "    'predicted_score': predictions,\n",
    "    'transcription': test_features['transcription']\n",
    "})\n",
    "\n",
    "# Create a submission dataframe with the required format\n",
    "submission = pd.DataFrame({\n",
    "    'filename': results['audio_file'],\n",
    "    'label': results['predicted_score'].round(1)  # Round to 1 decimal place if needed\n",
    "})\n",
    "\n",
    "# Save to CSV\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print(f\"Submission file created: submission.csv\")\n",
    "\n",
    "# Display the first few rows\n",
    "display(submission.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a917471b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pre-computed features from ./test_features.pkl\n"
     ]
    }
   ],
   "source": [
    "test_features = model.extract_features(data_type='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ae20694",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_files = model.test_data['audio_file'].tolist()\n",
    "extracted_files = test_features['audio_file'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "151d7f15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing files: ['audio_89.wav', 'audio_902.wav', 'audio_885.wav']\n"
     ]
    }
   ],
   "source": [
    "missing_files = [f for f in test_files if f not in extracted_files]\n",
    "print(f\"Missing files: {missing_files}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d6696ce3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['duration', 'mean_energy', 'tempo', 'zero_crossing_rate',\n",
       "       'spectral_centroid_mean', 'spectral_bandwidth_mean', 'rms_mean',\n",
       "       'mfcc1_mean', 'mfcc1_std', 'mfcc2_mean', 'mfcc2_std', 'mfcc3_mean',\n",
       "       'mfcc3_std', 'mfcc4_mean', 'mfcc4_std', 'mfcc5_mean', 'mfcc5_std',\n",
       "       'mfcc6_mean', 'mfcc6_std', 'mfcc7_mean', 'mfcc7_std', 'mfcc8_mean',\n",
       "       'mfcc8_std', 'mfcc9_mean', 'mfcc9_std', 'mfcc10_mean',\n",
       "       'mfcc10_std', 'mfcc11_mean', 'mfcc11_std', 'mfcc12_mean',\n",
       "       'mfcc12_std', 'mfcc13_mean', 'mfcc13_std', 'word_count',\n",
       "       'error_count', 'error_density', 'sentence_count',\n",
       "       'avg_sentence_length', 'avg_word_length', 'max_word_length',\n",
       "       'linguistic_quality', 'error_style', 'error_typographical',\n",
       "       'unique_words_ratio', 'comma_count', 'question_mark_count',\n",
       "       'exclamation_count', 'pronoun_count', 'article_count',\n",
       "       'conjunction_count', 'speech_rate', 'error_misspelling',\n",
       "       'error_uncategorized', 'error_grammar', 'error_duplication',\n",
       "       'error_locale_violation', 'error_whitespace'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names = model.model.feature_names_in_\n",
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d55c9ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.DataFrame(0, index=range(len(test_features)), columns=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "74b8c1df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared 201 samples with 57 features\n"
     ]
    }
   ],
   "source": [
    "for col in feature_names:\n",
    "    if col in test_features.columns:\n",
    "        X_test[col] = test_features[col].fillna(0)\n",
    "\n",
    "print(f\"Prepared {len(X_test)} samples with {len(feature_names)} features\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "541d6f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a complete submission dataframe with all test files\n",
    "# Start with the ones we have predictions for\n",
    "submission = pd.DataFrame({\n",
    "    'filename': results['audio_file'],\n",
    "    'label': results['predicted_score'].round(1)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ad461111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 3 missing files with default score: 3.8\n"
     ]
    }
   ],
   "source": [
    "default_score = results['predicted_score'].mean().round(1)\n",
    "for missing_file in missing_files:\n",
    "    submission = pd.concat([submission, pd.DataFrame({\n",
    "        'filename': [missing_file],\n",
    "        'label': [default_score]\n",
    "    })], ignore_index=True)\n",
    "\n",
    "    \n",
    "\n",
    "print(f\"Added {len(missing_files)} missing files with default score: {default_score}\")\n",
    "\n",
    "submission['label'] = submission['label'].clip(2, 5)\n",
    "submission['label'] = (submission['label'] * 2).round() / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "15c83a60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file created: submission.csv with 204 rows\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>audio_804.wav</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>audio_1028.wav</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>audio_865.wav</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>audio_774.wav</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>audio_1138.wav</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>audio_278.wav</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>audio_1212.wav</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>audio_178.wav</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>audio_542.wav</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>audio_248.wav</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         filename  label\n",
       "0   audio_804.wav    2.5\n",
       "1  audio_1028.wav    3.0\n",
       "2   audio_865.wav    3.0\n",
       "3   audio_774.wav    3.0\n",
       "4  audio_1138.wav    3.0\n",
       "5   audio_278.wav    3.5\n",
       "6  audio_1212.wav    3.5\n",
       "7   audio_178.wav    4.0\n",
       "8   audio_542.wav    3.0\n",
       "9   audio_248.wav    3.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total files in submission: 204\n",
      "Range of predictions: 2.5 to 5.0\n"
     ]
    }
   ],
   "source": [
    "submission.to_csv('submission.csv', index=False)\n",
    "print(f\"Submission file created: submission.csv with {len(submission)} rows\")\n",
    "\n",
    "# Display the first few rows and some stats\n",
    "display(submission.head(10))\n",
    "print(f\"Total files in submission: {len(submission)}\")\n",
    "print(f\"Range of predictions: {submission['label'].min()} to {submission['label'].max()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
